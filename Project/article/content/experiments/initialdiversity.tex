\subsection{Static experiments}
We perform two different static experiments, which differ in the way they constrain the initially generated population. 

\subsubsection{Initial similarity}
Here, we introduce the variable \emph{initial similarity}, which is a real value in the range $[0,1]$.
When making an initial population, an initial similarity of $\alpha$ means that $\alpha$ of the individuals in the population will have the exact same genotype, and $(1 - \alpha)$ of the individuals are completely random.
An initial similarity of \num{1} means that all genotypes are the same, and hence the traits of all individuals are the same as well. In this case, we expect the lowest diversity possible.
As initial similarity increases, more genotypes will be identical, and hence more individuals will have similar traits.
We therefore expect the diversity to decrease as initial similarity is increased.
An initial similarity of \num{0} means that all genotypes are random, and hence we expect the most diverse traits among individuals to be found here.

\subsubsection{Initial mutation}
Here, we introduce the variable \emph{initial mutation}, which is also a real value in the range $[0,1]$.
When making an initial population, an initial mutation of $\alpha$ affects the population in the following way.
A random genotype is created and given to every individual in the population, such that all individuals have an identical genotype.
Now, the bit string of each individual is mutated. Each bit will with probability $\alpha$ be set to a random boolean value. 
We expect to see increasingly different traits, as a result of mutating bit strings. 

\subsubsection{Results of initial similarity} The results of various initial similarity values shown in \cref{fig:initial-similarity} play along with our intuition. For each of the problems, each diversity measure's output gradually falls upon increasing the amount of similar individuals in the population. Interestingly enough, at an initial similarity of 0, we expect all diversity measures to output maximum diversity. Here, \dia{} outputs the maximum possible diversity of 1, whereas Hamming distance outputs a diversity that is only half of its maximum. One could assume that you could just double Hamming distance's diversity, but it is actually possible for the Hamming distance between two individuals to output 1, if every pair of bits are different. It seems that \dia{} captures the chaotic nature of a completely random population better than the other two measures, with a larger fall in diversity over time.
%
\input{drawings/initial-similarity-graphs}
%
\subsubsection{Results of initial mutation} By changing the initial mutation in a population, with the results shown in \cref{fig:initial-mutation}, we notice a larger difference between diversity measures. At an initial mutation rate of a mere \perc{1}, \dia{} takes a great leap compared to the other two measures. For Hamming distance, it is obvious that changing only a few bits in the genotypes will only cause a small change in diversity. This is because Hamming distance measures diversity based on genotypes. Consider for instance changing just a single bit of a chromosome. This bit could be a sign bit that causes a significant change to the neural network's traits, or it could cause no change at all. Hamming distance neglects this fact and produces the same diversity measure regardless of whether the bit caused a change of traits for the individual or not.

For the fitness-based diversity measure, it must be noted that the fitness values are dependent on the particular problem in question and how one chooses to define the fitness function. Consider for instance the problem of making an AI for the game Snake. We have experienced that if we define the fitness only in terms of how many pieces of food a snake collects, then about \perc{98} of randomly initialized individuals get a fitness value of 0. This is the reason why we chose a fitness function that also takes into account the number of steps a snake has been alive. Despite yielding more diverse fitness values, it also notably increased the fitness values obtained after just 100 iterations. This does not mean that a fitness function cannot reflect differences in traits, but it shows that how one defines the fitness function is crucial, if one wishes to catch the different traits among individuals.
%
\input{drawings/initial-mutation-graphs}
