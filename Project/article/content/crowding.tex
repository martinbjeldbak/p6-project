\subsection{Crowding}
%Many methods have been proposed to overcome the problem of gradually decreasing diversity through generations. 
Methods to overcome decreasing diversity, include inserting random immigrants (randomly initialized individuals)~\cite{Cobb93geneticalgorithms}, using complex population structures to lower the gene flow, and the use of special selection procedures~\cite{ursem2002diversity}. The latter is known as crowding~\cite{DeJong:1975:ABC:907087}. How a particular crowding method works is commonly described by a replacement rule.

The replacement rule determines which individuals of the $i$th generation $G_i$,
and their offspring $O_i$ are selected to form the the next generation $G_{i+1}$.

\subsubsection{Greedy replacement rule}
Common descriptions of GAs, that do not try to account for premature convergence,
are often making the generation $G_i$ from the $n$ most fit individuals from $G_{i-1} \cup O_{i-1}$, where $\lvert G_x \rvert = n$ for all $x$~\cite{masterThesisGANN}.
We will refer to this as the \emph{Greedy replacement rule}.

%\subsubsection{Probabilistic crowding replacement rule}
%The \emph{probabilistic crowding replacement rule}~\cite{Mengshoel_and_Goldberg:1999} can be described by the formula:
%
%\[
%  p(x) = \frac{f\left(x\right)}{f\left(x\right)+f\left(y\right)}
%\]
%
%where $p(x)$ denotes the chance that individual $x$ replaces individuals $\set{x, y}$, and $f(i)$ is the fitness of individual $i%$. This rule can easily be generalized for larger sets. Consider two individuals from the generation $G_i$ who have together %produced $y$ of the individuals in $O_i$.
%To avoid that these $2+y$ similar individuals are all selected for the next generation $G_{i+1}$, the probabilistic crowding %replacement rule can be used to select only $y$ of these individuals to survive, in an attempt to maintain a higher diversity.

\subsubsection{Ancestor Elitism replacement rule}
Ancestor Elitism is similar to $(\mu + \lambda)$ and Generation Gap algorithms, but it was developed independently of these algorithms~\cite[p. 34, p. 50]{Luke2013Metaheuristics}.

The next generation $G_{i+1}$ is made from generation $G_i$ as follows:
Every individual from $G_i$ is put into $G_{i+1}$.
Any individual in $O_i$ who has only a single parent (made from mutation) and is more fit than its parent, will replace that parent in $G_{i+1}$.
Any individual in $O_i$ who has two parents (made from crossover) and is more fit than both of its parents, will replace both parents in $G_{i+1}$ by itself and a random immigrant.
Finally, the 50 \% least fit individuals in $G_{i+1}$ is replaced by random immigrants.


\subsubsection{Single Parent Elitism replacement rule}
Single Parent Elitism is similar to Restricted Tournament Selection, but was developed indepentdently of this method~\cite[p. 132]{Luke2013Metaheuristics}.

$G_{i+1}$ is made from $G_i$ as follows:
Every individual from $G_i$ is put into $G_{i+1}$.
Any individual in $O_i$ who has only a single parent (made from mutation) and is more fit than its parent, will replace that parent in $G_{i+1}$.
Any individual in $O_i$ who has two parents (made from crossover), and is more fit than a randomly chosen parent, will replace its parent in $G_{i+1}$ by itself.

\subsubsection{Mass Extinction Explore Exploit replacement rule}
Inspired by the changes between exploration and exploitation phases used by Ursem~\cite{ursem2002diversity}, we introduce the following replacement rule, which we will refer to as the \emph{Mass Extinction Explore Exploit} (MEEE) replacement rule.
The MEEE replacement rule performs a mass extinction when the diversity drops below a threshold.
$G_{i+1}$ is made from $G_i$ as follows:

If $d(G_i) < \alpha$, replace the $\frac{n}{2}$ least fit individuals from $G_i$ by random immigrants, where $n = \lvert G_i \rvert$.
Use the \emph{Single Parent Elitism} replacement rule on $(G_i, O_i)$.

Where $d(G)$ denotes the diversity of a generation, and $\alpha$ is a threshold. 


%\paragraph{Roulette wheel selection}
%Also known as fitness proportionate selection, uses the fitness value of each individual to associate a probability of being selected to procreate. The probabilities are calculated to give the most fit individual the largest probability to be selected. We define $\fit_i$ to be the fitness of individual $i$, and the probability for selection is then calculated by $p_i = \frac{\fit_i}{\Phi}$, where $\Phi = \sum_{j=1}^{I} \fit_j$, and $I$ is the total number of individuals~\cite{tang1996genetic, koza1992genetic}. Using this method, the most fit individuals have the highest probability to be selected, while the least fit individuals have the lowest probability.
%
%Imagine a roulette wheel that is spun. The individual that is most fit might cover \perc{38} of the entire wheel, while the rest of the individuals combined have \perc{62} chance. It is obvious that the fittest individual will be selected most often.
%
%\paragraph{Stochastic Universal Sampling}
%
%This policy is similar to roulette wheel selection, with one exception. When individuals are selected for procreation, pointers are used to choose the individuals, instead of randomly choosing an individual. The number of pointers, $P$, is equal to the number of individuals for the next generation, and the pointers are equally spaced. The first pointer is placed at a random position in the range $\left[0, \frac{1}{P}\right]$, and the space between each of the following pointers is equal to $\frac{1}{P}$. Each pointer then points to an individual, and these individuals are selected for procreation, possibly skipping individuals~\cite{baker1987reducing}.
%
%\paragraph{Reward-based selection}
%
%Individuals have an associated reward, which is computed as the sum of the individual's reward and the reward of its parents. If the individual is selected for the next generation, then the individual and its parents receive a reward. The probability for an individual to be selected is proportional to the cumulative reward. There are different functions to calculate a reward~\cite{loshchilov2011not}.
%
%\paragraph{Tournament selection}
%
%As the name suggest, this policy works as any other tournament. It involves running several tournaments, and the winner of each tournament is chosen to procreate. The individuals compete to solve the given problem optimally, and the winner is selected for breeding~\cite{miller1996genetic}.
%
