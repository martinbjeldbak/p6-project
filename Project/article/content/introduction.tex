\section{Introduction}
For many problems in computer science, a greedy strategy will not always lead to the best result. Such a strategy is one where each step taken is the step that looks most promising at the moment. As an example, if a mountain climber wants to climb to the highest peak in the Himalayas, a greedy strategy is to move in any direction he think is the best, as long as he climbs up, and never down. Using this strategy, he is definitely able to climb up somewhere, but once he reaches a peak, he might discover an even greater peak he could not see before. Unfortunately, his strategy is to never back down, so now he is stuck at what we call a local optimum. What he wanted was the global optimum --- the highest mountain of all.
 
Genetic algorithms (GA) can be used to search for a global optimum in many types of problems, e.g.\ optimization problems. A genetic algorithm manages a number of individuals, which constitute a population. Each of these individuals represents a solution to a given problem. Individuals are conceptually just a chromosome consisting of different genes. In a GA, individuals are represented internally as bit strings. There are many ways in which the bit string can be interpreted to form a solution to the problem in question. Often, neural networks are chosen as individuals and are decoded from the chromosome. A neural network takes a number of inputs, does some internal calculations, and yields a number of outputs, which can be interpreted as a solution to the problem. How the bit string is interpreted determines how these calculations are carried out. For the particular problem of adding two integers, the neural network can be given the two integers $s$ and $t$ as input, and output a single value, which ideally should be $s+t$. The goal of GAs is to find an optimal neural network to solve the addition as quickly as possible.

Two individuals in a population may solve a problem completely different.
Individuals in a GA procreate to form offspring. The solution an offspring individual proposes will typically combine traits from both its parents. Hopefully, the combination of these traits will constitute a better solution to the particular problem in question. A fitness value is given to each individual to indicate how well it solves the problem.

To identify a constructive combination of traits, a diverse set of individuals is required. If diversity is not maintained, only a local optimum of the available traits in the population will be explored, and a global optimum might never be found~\cite{ursem2002diversity}.

We believe it is essential that a diversity measure reflects the difference in traits among individuals. By concentrating on neural networks as individuals, we develop a new diversity measure, that as we will see, is not affected by pitfalls in traditional diversity measures.

Since a \emph{trait} is a rather vague term, we introduce a clear definition of traits among neural networks: ``\emph{two neural networks have different traits if they for some input produce different outputs}''. We now argue why we think that neither fitness-based nor genotypic diversity measures catch this trait diversity. 

% Motivation for why fitness-based and genotypic suck
Consider two individuals who try to find the highest peak on an elevation map, where the fitness of each individual is based on the height of the peak they return. The two individuals might have completely different strategies causing them to get stuck on two different peaks. If both peaks happen to have the same height, the two individuals will have the same fitness, and hence a fitness-based diversity measure will return a low diversity, even though the two individuals have different traits.

Two individuals of different genotypes can have the same behaviour, which means they yield the same output on any input. An example of such two neural networks is shown in \cref{fig:entire-eqnetwork}. No matter what input they receive, their output will always be the same. They are genotypic diverse because their bit strings are different, but they are not trait diverse at all.
%
\input{floats/eqnetworks}
%
%Many existing methods which aim to increase diversity, require a lot of computational power \citpls{}. We will develop a method that is computationally inexpensive, yet maintains a high diversity in a population. Common methods for measuring the phenotypic diversity of a population only take into account the fitness of each individual \citpls{}. We develop a method for measuring phenotypic diversity that takes into account the different traits among individuals. 
We develop a new method for measuring phenotypic diversity in genetic algorithms using neural networks as individuals. We claim that our method better reflects different traits among the individuals. Furthermore, we use our method to explore how different replacement rules affect the diversity of a population.

%related work
Concepts and applications of Genetic Algorithms (GAs) are described in \cite{Cobb93geneticalgorithms,DeJong:1975:ABC:907087,Luke2013Metaheuristics,Syswerda:1989:UCG:645512.657265,ursem2002diversity,fogarty,Whitley:1989:GAS:93126.93169,1250187}.
The use of diversity maintenance in GAs is discussed in \cite{diaz2007empirical,Zitzler00comparisonof,Darwen00doesextra,1266373}, and measures of population diversity are described in \cite{Nguyen:2006:ASPGP,simpson1949measurement}.
Combining GAs and Neural networks is described in \cite{masterThesisGANN}.

\Cref{sec:preliminaries} introduces the concepts used in our diversity measure, and can be skipped if the reader is knowledgeable about genetic algorithms and neural networks. \Cref{sec:nntd} describes our diversity measure, which is evaluated and compared with other measures in \cref{sec:experiments}. In \cref{sec:conclusion}, we evaluate our solution.
