\section{Introduction}
For many problems in computer science, a greedy strategy will not always lead to an optimal result. A greedy strategy chooses the next step by considering how promising each step is at that given moment. As an example, if a mountain climber is randomly placed by a helicopter in the midst of peaks, and he wants to reach the highest of these peaks, a greedy strategy would be to move in any direction he think is the best, as long as he climbs upwards and never downwards. Using this strategy, he is definitely able to climb up some peak, but the chance that this peak is the highest one is very little. Unfortunately, his strategy is to never back down, so now he is stuck at what we call a local optimum. What he wanted was the global optimum, the highest peak.
 
Genetic algorithms (GAs) can be used to search for a global optimum in many types of problems, such as optimization problems. A GA manages a number of individuals, which together constitute a population. Each of the individuals represents a candidate solution to the same problem. Neural networks, among other data structures, can be chosen as individuals.
In this article, we will only use neural networks as individuals, and hence use the terms \emph{neural network} and\emph{individual} interchangeably.
A neural network takes a number of inputs, do some internal calculations, and then yield a number of outputs.
The neural network as a whole can be interpreted as a solution to the problem.
For instance, for the particular problem of adding two integers, the neural network can take two integers $s$ and $t$ as input, and output a single value, which ideally should equal $s + t$.

Most often, the individuals in a GA do not adequately solve the problem in question.
However, different individuals may have good solutions to different aspects of the problem.
Individuals maintained by the GA procreate to form offspring that combine the best traits from both its parents. Intuitively, the combination of these traits constitutes a better solution to the given problem. Each individual has a fitness value, which indicates how adequately it solves the problem in question.

To identify a constructive combination of traits, a diverse set of individuals is required. If diversity is not maintained, only a local optimum of the population's available traits will be explored, and a global optimum might never be found~\cite{ursem2002diversity,Darwen00doesextra}.

We believe it is essential that a diversity measure reflects the difference in traits among individuals. Since a \emph{trait} is a rather vague term, we introduce a clear definition of traits among neural networks: ``\emph{two neural networks have different traits, if they for some input produce different outputs}''. We now argue why we think that neither fitness-based nor genotypic diversity measures catch a diversity among traits, or \emph{trait diversity}.
%By concentrating on neural networks as individuals, we develop a new diversity measure that, as we will see, is not affected by pitfalls in the traditional diversity measures: Hamming distance and fitness-based diversity measure. Hamming distance, a genotypic diversity measure, is concerned with the representation of the individuals, while fitness-based, a phenotypic diversity measure, is concerned with the behaviour of the individuals, which is often measured based on their fitness.
%If two individuals have a different , we say that they have different genotypes. If the neural network they encode produces a different output for some input, we say they have different phenotypes.

Genotypic diversity is concerned with the representation of the individuals, while phenotypic diversity is concerned with their behaviour of the individuals, which is often measured based on their fitness. Consider two individuals who try to find the highest peak on an elevation map, where the fitness of each individual is proportionate to the height of the peak they return. The two individuals might have completely different strategies, causing them to get stuck on two different peaks. If both peaks happen to have the same height, the two individuals will have the same fitness, and hence a fitness-based diversity measure will return a low diversity, even though the two individuals have different traits.

Two individuals of different genotypes can have the same traits. An example of such two neural networks is shown in \cref{fig:entire-eqnetwork}. No matter what input they receive, their output will always be the same. They are genotypically diverse, because their genetic structure is different, but they are not trait diverse, because they produce the same output. The genetic structure could be represented as bit string as shown in \cref{fig:entire-eqnetwork}.
%
\input{floats/eqnetworks}
%
%Many existing methods which aim to increase diversity, require a lot of computational power \citpls{}. We will develop a method that is computationally inexpensive, yet maintains a high diversity in a population. Common methods for measuring the phenotypic diversity of a population only take into account the fitness of each individual \citpls{}. We develop a method for measuring phenotypic diversity that takes into account the different traits among individuals. 
We develop a new method for measuring phenotypic diversity in GAs using neural networks as individuals. We claim that our method better reflects different traits among the individuals.

This paper is organized as follows. \Cref{sec:preliminaries} introduces the concepts used in our diversity measure, and can be skipped if the reader knows about genetic algorithms and neural networks. \Cref{sec:nntd} describes our diversity measure, which is experimentally evaluated and compared to other measures in \cref{sec:experiments}. In \cref{sec:conclusion} we evaluate \dia.

\subsection{Related work}
Concepts and applications of GAs are described in \cite{Cobb93geneticalgorithms,DeJong:1975:ABC:907087,Luke2013Metaheuristics,Syswerda:1989:UCG:645512.657265,ursem2002diversity,fogarty,Whitley:1989:GAS:93126.93169,1250187}. The use of diversity maintenance in GAs is discussed in \cite{diaz2007empirical,Zitzler00comparisonof,Darwen00doesextra,1266373}, and measures of population diversity are described in \cite{Nguyen:2006:ASPGP,simpson1949measurement}. Combining GAs and neural networks is described in \cite{masterThesisGANN}.
